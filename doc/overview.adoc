
= Overview

== Basic concept

This runtime supports 2 running modes.
First `accelerator mode` is designed for cooperative systems that are consists from host and accelerator device side applications.
Second `standalone mode` is designed for independent small embedded device applications.

=== Accelerator mode

In this mode device works as accelerator.
Host application passes some heavy tasks and related data to device and device will process quickly on the device side.
This runtime works as communication layers between host and device and as simple OS for accelerator device side applications.
Here is an example usecase of host and device.

[plantuml]
----
@startuml
participant "Host" as Host
participant "Accelerator Device" as Acc

activate Host

Host -> Acc : App + Runtime binary
Host -> Acc : Put input data/parameters
Host -> Acc : Run accelerator
activate Acc
deactivate Host

Acc -> Acc : Do heavy task

Acc -> Host : Notify finished
activate Host
deactivate Acc
Host -> Acc : Get output data/results
@enduml
----

=== Standalone mode

In this mode, host side application is not required (optional) becuase device side enable to run standalone.
This runtime can be used for simple baremetal runtime for small embedded devices.

[plantuml]
----
@startuml
participant "Embedded Device" as Dev

Dev -> Dev : Reset
activate Dev

Dev -> Dev : Do some task

Dev -> Dev : Finished
deactivate Dev

@enduml
----


== Design goals

* Easy to use
  ** Fully support POSIX APIs by full C library for Linux
  ** Reuse almost build environment for Linux
* Lightweigt
  ** Implement minimum features for smaller footprint than Linux
  ** Limit maximum number of threads up to physical cores to remove the thread scheduler (and it's overhead) from runtime
* Single task
  ** Concentrate to run the heavy calculation task
  ** Accept to drop some typical OS features (I/O, signals, ...)


== Application designs

A device side application needs to be cross compiled on PC before running.
An application that is statically linked with cross C/C++ libraries and this runtime library is packed to one binary.

[plantuml]
----
@startuml
file dev_app_src as "User app (C/C++, Device)"
file dev_app as "User app binary (Device)" {
    file dev_app_bin as "User kernel (Device)"
    file dev_libc as "C/C++ library (Device)"
    file dev_lib as "Runtime library (Device)"
}
rectangle dev_compiler as "GCC/LLVM (Cross)"

dev_app_src --> dev_compiler
dev_compiler --> dev_app_bin : Offline compile on Host
dev_app_bin .. dev_libc : Static link
dev_app_bin .. dev_lib : Static link
@enduml
----

A host side application is dynamically linked with host side C/C++ and runtime libraries.
There are source codes of host side runtime library in another repository.

[plantuml]
----
@startuml
file host_app_src as "User app (C/C++, Host)"
file host_libc as "C/C++ library (Host)"
file host_lib as "Runtime library (Host)"
file host_app_bin as "User app binary (Host)"
rectangle host_compiler as "GCC/LLVM (Host)"

host_app_src --> host_compiler
host_compiler --> host_app_bin : Compile
host_app_bin .. host_libc : Dynamic link
host_app_bin .. host_lib : Dynamic link
@enduml
----


== Block diagram

This picture shows almost modules and their communication paths in accelerator mode.

[plantuml]
----
@startuml
rectangle host as "Host" {
    rectangle host_app_bin as "User app binary (Host)"
    rectangle host_runtime as "Runtime library (Host)" {
        rectangle host_lib as "Runtime (Host)"
        rectangle host_drv as "HW driver (Host, user mode)"
    }
    rectangle host_os as "Host OS (Linux)" {
        rectangle host_drv_common as "HW driver layer"
    }
    rectangle host_hw as "Host HW"

    file dev_app_gen as "User app binary (Device)"
}

rectangle device as "Device" {
    rectangle dev_app_bin as "User kernel (Device)"
    rectangle dev_runtime as "Runtime library (Device)" {
        rectangle dev_lib as "Runtime (Device)"
        rectangle dev_drv as "HW driver (Device)"
    }
    rectangle dev_hw as "Device HW"
}

host_app_bin <--> host_lib : OpenCL API
host_lib <--> host_drv : Original HW API
host_drv <--> host_drv_common
host_drv_common <--> host_hw

dev_app_gen ..> dev_app_bin : Transfer

dev_app_bin <--> dev_lib : POSIX API, System call
dev_lib <--> dev_drv : Original HW API
dev_drv <--> dev_hw

host_lib <--> dev_lib : Original protocol, GDB protocol, ...
host_hw <--> dev_hw : PCIe, TCP/IP, ...
@enduml
----


== Pros and Cons (vs. baremetal, RTOS)

This runtime versus typical baremetal environment.

Pros

* Minimum porting effert
  ** Programmers can use Linux application program environment
  ** No special headers, no strange defines, no API layer limitations from programmers point of view

Cons

* Overhead
  ** An application uses runtime service directly (or with low overhead) when run on RTOS
  ** On the other hand this runtime services are slower than RTOS because an application need to use services via system calls same as Linux
  ** Need large ROM (for text, read only data) and RAM area size mainly required by full C library


== Non-supported features

Currently we dropped some typical OS features. It is better to use RTOS or rich OSes if you need these rich features.

* MMU, virtual memory
* Multiple priviledged mode
* Multiple processes
* Filesystem


== Special rules for application build

Need to add some linker options into Linux application build script when you build the applications for this runtime.

* Statically linked
  ** Not support PIC
* Use special linker script
  ** Use fixed entry point
  ** Use special entry function _reset() for detail please refer internal documents
  ** Use configured memory maps for each HW
* Additional library for runtime
  ** Use "whole-archive" option

This is an example of hello world application for this runtime.
Normal build process for RISC-V Linux is here:

[source,sh]
----
riscv64-unknown-linux-gnu-gcc -Wall -O2 hello.c -mcmodel=medany
----

Need 4 options to build an application for this runtime.

* Statically linked
  ** -static option
* Use special linker script
  ** -Wl,-T option: Specify the path to linker script
  ** This linker script is automatically generated when you build runtime library
* Additional library for runtime
  ** -L option: Specify the path to runtime library
  ** -Wl,--whole-archive option: Specify runtime library and use whole symbols in the library if no one refer them

[source,sh]
----
DIR_SYSROOT=./sysroot \
riscv64-unknown-linux-gnu-gcc -Wall -O2 hello.c -mcmodel=medany \
  -static \
  -L ${DIR_SYSROOT}/lib \
  -Wl,-T,${DIR_SYSROOT}/include/bmetal/generated/linker_gen.ld \
  -Wl,--whole-archive,-lbmetal_crt,--no-whole-archive
----
